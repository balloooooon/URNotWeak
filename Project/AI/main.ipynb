{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMKz/bxzZfbTbaieDCibQsK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":21,"metadata":{"id":"OHTOdVDTh8jl","executionInfo":{"status":"ok","timestamp":1691377035165,"user_tz":-540,"elapsed":294,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}}},"outputs":[],"source":["# from flask import Flask, request,jsonify\n","# from werkzeug.utils import secure_filename\n","# from flask import send_file\n","# import os\n","# import sys\n","# # from models.e4e import predict\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# sys.path.append('/content/drive/MyDrive/drug/ML')\n","\n","# !pip install flask-ngrok\n","# !pip install pyngrok==4.1.1\n","# !ngrok authtoken '294dzGF6SRGFWn5l0brOtz37HvR_2WRzjVis8V5QuYW9A7Gda'\n","# !pip install ffmpeg-python\n","# from flask_ngrok import run_with_ngrok\n","\n","\n","\n","\n","# install requirements\n","# !git clone https://github.com/yuval-alaluf/restyle-encoder.git $restyle_dir\n","\n","# !wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n","# !sudo unzip ninja-linux.zip -d /usr/local/bin/\n","# !sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n","\n","# !pip install ftfy regex tqdm\n","# !pip install git+https://github.com/openai/CLIP.git\n","\n","# !git clone https://github.com/NVlabs/stylegan2-ada/ $stylegan_ada_dir\n","# !git clone https://github.com/rinongal/stylegan-nada.git $stylegan_nada_dir\n","# !PYTHONPATH=$py_path python $convert_script --repo $stylegan_ada_dir --gen $pretrained_model_dir/$file_name\n","\n","# !pip install import_ipynb\n","# import import_ipynb\n","# from stylegan_nada2 import predict"]},{"cell_type":"code","source":["import os\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","pretrained_model_dir = os.path.join(\"/content\", \"models\")\n","os.makedirs(pretrained_model_dir, exist_ok=True)\n","\n","restyle_dir = os.path.join(\"/content\", \"restyle\")\n","stylegan_ada_dir = os.path.join(\"/content\", \"stylegan_ada\")\n","stylegan_nada_dir = os.path.join(\"/content\", \"stylegan_nada\")\n","\n","output_dir = os.path.join(\"/content\", \"output\")\n","\n","output_model_dir = os.path.join(output_dir, \"models\")\n","output_image_dir = os.path.join(output_dir, \"images\")\n","\n","download_with_pydrive = True #@param {type:\"boolean\"}\n","\n","class Downloader(object):\n","    def __init__(self, use_pydrive):\n","        self.use_pydrive = use_pydrive\n","\n","        if self.use_pydrive:\n","            self.authenticate()\n","\n","    def authenticate(self):\n","        auth.authenticate_user()\n","        gauth = GoogleAuth()\n","        gauth.credentials = GoogleCredentials.get_application_default()\n","        self.drive = GoogleDrive(gauth)\n","\n","    def download_file(self, file_id, file_dst):\n","        if self.use_pydrive:\n","            downloaded = self.drive.CreateFile({'id':file_id})\n","            downloaded.FetchMetadata(fetch_all=True)\n","            downloaded.GetContentFile(file_dst)\n","        else:\n","            !gdown --id $file_id -O $file_dst\n","\n","downloader = Downloader(download_with_pydrive)\n","\n","# install requirements\n","!git clone https://github.com/yuval-alaluf/restyle-encoder.git $restyle_dir\n","\n","!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n","!sudo unzip ninja-linux.zip -d /usr/local/bin/\n","!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n","\n","!pip install ftfy regex tqdm\n","!pip install git+https://github.com/openai/CLIP.git\n","\n","!git clone https://github.com/NVlabs/stylegan2-ada/ $stylegan_ada_dir\n","!git clone https://github.com/rinongal/stylegan-nada.git $stylegan_nada_dir\n","\n","from argparse import Namespace\n","\n","import sys\n","import numpy as np\n","\n","from PIL import Image\n","\n","import torch\n","import torchvision.transforms as transforms\n","\n","sys.path.append(restyle_dir)\n","sys.path.append(stylegan_nada_dir)\n","sys.path.append(os.path.join(stylegan_nada_dir, \"ZSSGAN\"))\n","\n","device = 'cuda'\n","\n","%load_ext autoreload\n","%autoreload 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sI9BUr0xyUfX","executionInfo":{"status":"ok","timestamp":1691377199556,"user_tz":-540,"elapsed":50759,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}},"outputId":"af31beb6-f4fe-488f-ba87-2cf44bc66ce0"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path '/content/restyle' already exists and is not an empty directory.\n","--2023-08-07 02:59:09--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230807%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230807T025909Z&X-Amz-Expires=300&X-Amz-Signature=c69a624ec6e6a93b01d402a00747b127cb3b70333a09faef0cc9924e27c73058&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n","--2023-08-07 02:59:09--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230807%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230807T025909Z&X-Amz-Expires=300&X-Amz-Signature=c69a624ec6e6a93b01d402a00747b127cb3b70333a09faef0cc9924e27c73058&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 77854 (76K) [application/octet-stream]\n","Saving to: ‘ninja-linux.zip.3’\n","\n","ninja-linux.zip.3   100%[===================>]  76.03K  --.-KB/s    in 0.009s  \n","\n","2023-08-07 02:59:09 (8.65 MB/s) - ‘ninja-linux.zip.3’ saved [77854/77854]\n","\n","Archive:  ninja-linux.zip\n","replace /usr/local/bin/ninja? [y]es, [n]o, [A]ll, [N]one, [r]ename: Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.1.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.6)\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-ht10qiiv\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-ht10qiiv\n","  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.65.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.15.2+cu118)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip==1.0) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip==1.0) (16.0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n","fatal: destination path '/content/stylegan_ada' already exists and is not an empty directory.\n","fatal: destination path '/content/stylegan_nada' already exists and is not an empty directory.\n","The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}]},{"cell_type":"code","source":["source_model_type = 'ffhq' #@param['ffhq', 'cat', 'dog', 'church', 'horse', 'car']\n","\n","source_model_download_path = {\"ffhq\":   \"1EM87UquaoQmk17Q8d5kYIAHqu0dkYqdT\",\n","                              \"cat\":    \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/afhqcat.pkl\",\n","                              \"dog\":    \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/afhqdog.pkl\",\n","                              \"church\": \"1iDo5cUgbwsJEt2uwfgDy_iPlaT-lLZmi\",\n","                              \"car\":    \"1i-39ztut-VdUVUiFuUrwdsItR--HF81w\",\n","                              \"horse\":  \"1irwWI291DolZhnQeW-ZyNWqZBjlWyJUn\"}\n","\n","model_names = {\"ffhq\":   \"ffhq.pt\",\n","               \"cat\":    \"afhqcat.pkl\",\n","               \"dog\":    \"afhqdog.pkl\",\n","               \"church\": \"stylegan2-church-config-f.pkl\",\n","               \"car\":    \"stylegan2-car-config-f.pkl\",\n","               \"horse\":  \"stylegan2-horse-config-f.pkl\"}\n","\n","download_string = source_model_download_path[source_model_type]\n","file_name = model_names[source_model_type]\n","pt_file_name = file_name.split(\".\")[0] + \".pt\"\n","\n","dataset_sizes = {\n","    \"ffhq\":   1024,\n","    \"cat\":    512,\n","    \"dog\":    512,\n","    \"church\": 256,\n","    \"horse\":  256,\n","    \"car\":    512,\n","}\n","\n","if not os.path.isfile(os.path.join(pretrained_model_dir, file_name)):\n","    print(\"Downloading chosen model...\")\n","\n","    if download_string.endswith(\".pkl\"):\n","        !wget $download_string -O $pretrained_model_dir/$file_name\n","    else:\n","        downloader.download_file(download_string, os.path.join(pretrained_model_dir, file_name))\n","\n","if not os.path.isfile(os.path.join(pretrained_model_dir, pt_file_name)):\n","    print(\"Converting sg2 model. This may take a few minutes...\")\n","\n","    tf_path = next(filter(lambda x: \"tensorflow\" in x, sys.path), None)\n","    py_path = tf_path + f\":{stylegan_nada_dir}/ZSSGAN\"\n","    convert_script = os.path.join(stylegan_nada_dir, \"convert_weight.py\")\n","    !PYTHONPATH=$py_path python $convert_script --repo $stylegan_ada_dir --gen $pretrained_model_dir/$file_name"],"metadata":{"id":"-0FA07gVybiT","executionInfo":{"status":"ok","timestamp":1691377127536,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from ZSSGAN.model.ZSSGAN import ZSSGAN\n","\n","import numpy as np\n","\n","import torch\n","\n","from tqdm import notebook\n","\n","from ZSSGAN.utils.file_utils import save_images, get_dir_img_list\n","from ZSSGAN.utils.training_utils import mixing_noise\n","\n","from IPython.display import display\n","\n","source_class = \"Photo\" #@param {\"type\": \"string\"}\n","target_class = \"Zombie\" #@param {\"type\": \"string\"}\n","\n","style_image_dir = \"\" #@param {'type': 'string'}\n","\n","target_img_list = get_dir_img_list(style_image_dir) if style_image_dir else None\n","\n","improve_shape = False #@param{type:\"boolean\"}\n","\n","model_choice = [\"ViT-B/32\", \"ViT-B/16\"]\n","model_weights = [1.0, 0.0]\n","\n","if improve_shape or style_image_dir:\n","    model_weights[1] = 1.0\n","\n","mixing = 0.9 if improve_shape else 0.0\n","\n","auto_layers_k = int(2 * (2 * np.log2(dataset_sizes[source_model_type]) - 2) / 3) if improve_shape else 0\n","auto_layer_iters = 1 if improve_shape else 0\n","\n","training_iterations = 51 #@param {type: \"integer\"}\n","output_interval     = 50 #@param {type: \"integer\"}\n","save_interval       = 0 #@param {type: \"integer\"}\n","\n","training_args = {\n","    \"size\": dataset_sizes[source_model_type],\n","    \"batch\": 2,\n","    \"n_sample\": 4,\n","    \"output_dir\": output_dir,\n","    \"lr\": 0.002,\n","    \"frozen_gen_ckpt\": os.path.join(pretrained_model_dir, pt_file_name),\n","    \"train_gen_ckpt\": os.path.join(pretrained_model_dir, pt_file_name),\n","    \"iter\": training_iterations,\n","    \"source_class\": source_class,\n","    \"target_class\": target_class,\n","    \"lambda_direction\": 1.0,\n","    \"lambda_patch\": 0.0,\n","    \"lambda_global\": 0.0,\n","    \"lambda_texture\": 0.0,\n","    \"lambda_manifold\": 0.0,\n","    \"auto_layer_k\": auto_layers_k,\n","    \"auto_layer_iters\": auto_layer_iters,\n","    \"auto_layer_batch\": 8,\n","    \"output_interval\": 50,\n","    \"clip_models\": model_choice,\n","    \"clip_model_weights\": model_weights,\n","    \"mixing\": mixing,\n","    \"phase\": None,\n","    \"sample_truncation\": 0.7,\n","    \"save_interval\": save_interval,\n","    \"target_img_list\": target_img_list,\n","    \"img2img_batch\": 16,\n","    \"channel_multiplier\": 2,\n","    \"sg3\": False,\n","    \"sgxl\": False,\n","}\n","\n","args = Namespace(**training_args)\n","\n","print(\"Loading base models...\")\n","net = ZSSGAN(args)\n","print(\"Models loaded! Starting training...\")\n","\n","g_reg_ratio = 4 / 5\n","\n","g_optim = torch.optim.Adam(\n","    net.generator_trainable.parameters(),\n","    lr=args.lr * g_reg_ratio,\n","    betas=(0 ** g_reg_ratio, 0.99 ** g_reg_ratio),\n",")\n","\n","# Set up output directories.\n","sample_dir = os.path.join(args.output_dir, \"sample\")\n","ckpt_dir   = os.path.join(args.output_dir, \"checkpoint\")\n","\n","os.makedirs(sample_dir, exist_ok=True)\n","os.makedirs(ckpt_dir, exist_ok=True)\n","\n","seed = 3 #@param {\"type\": \"integer\"}\n","\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","\n","# Training loop\n","fixed_z = torch.randn(args.n_sample, 512, device=device)\n","\n","for i in notebook.tqdm(range(args.iter)):\n","    net.train()\n","\n","    sample_z = mixing_noise(args.batch, 512, args.mixing, device)\n","\n","    [sampled_src, sampled_dst], clip_loss = net(sample_z)\n","\n","    net.zero_grad()\n","    clip_loss.backward()\n","\n","    g_optim.step()\n","\n","    if i % output_interval == 0:\n","        net.eval()\n","\n","        with torch.no_grad():\n","            [sampled_src, sampled_dst], loss = net([fixed_z], truncation=args.sample_truncation)\n","\n","            if source_model_type == 'car':\n","                sampled_dst = sampled_dst[:, :, 64:448, :]\n","\n","            grid_rows = 4\n","\n","            save_images(sampled_dst, sample_dir, \"dst\", grid_rows, i)\n","\n","            img = Image.open(os.path.join(sample_dir, f\"dst_{str(i).zfill(6)}.jpg\")).resize((1024, 256))\n","            display(img)\n","\n","    if (args.save_interval > 0) and (i > 0) and (i % args.save_interval == 0):\n","        torch.save(\n","            {\n","                \"g_ema\": net.generator_trainable.generator.state_dict(),\n","                \"g_optim\": g_optim.state_dict(),\n","            },\n","            f\"{ckpt_dir}/{str(i).zfill(6)}.pt\",\n","        )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"id":"pwEsk1f9yf8C","executionInfo":{"status":"error","timestamp":1691377215243,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}},"outputId":"c589d7e2-e01e-47c5-aca9-b0eae70002db"},"execution_count":27,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-20a175a06c0d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mZSSGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZSSGAN\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mZSSGAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/drug/ML/ZSSGAN/model/ZSSGAN.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mZSSGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msg2_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mZSSGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriteria\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_loss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCLIPLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# import ZSSGAN.legacy as legacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/drug/ML/ZSSGAN/model/sg2_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFusedLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfused_leaky_relu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupfirdn2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2d_gradfix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/stylegan_nada/ZSSGAN/op/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfused_act\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFusedLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfused_leaky_relu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mupfirdn2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mupfirdn2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/stylegan_nada/ZSSGAN/op/fused_act.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodule_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m fused = load(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"fused\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     sources=[\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         ...     verbose=True)\n\u001b[1;32m   1283\u001b[0m     '''\n\u001b[0;32m-> 1284\u001b[0;31m     return _jit_compile(\n\u001b[0m\u001b[1;32m   1285\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_exec_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_import_module_from_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_python_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_import_module_from_library\u001b[0;34m(module_name, path, is_python_module)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_from_file_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: /root/.cache/torch_extensions/py310_cu118/fused/fused.so: cannot open shared object file: No such file or directory","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["truncation = 0.7 #@param {type:\"slider\", min:0, max:1, step:0.05}\n","\n","samples = 9\n","\n","with torch.no_grad():\n","    net.eval()\n","    sample_z = torch.randn(samples, 512, device=device)\n","\n","    [sampled_src, sampled_dst], loss = net([sample_z], truncation=truncation)\n","\n","    if source_model_type == 'car':\n","        sampled_dst = sampled_dst[:, :, 64:448, :]\n","\n","    grid_rows = int(samples ** 0.5)\n","\n","    save_images(sampled_dst, sample_dir, \"sampled\", grid_rows, 0)\n","\n","    display(Image.open(os.path.join(sample_dir, f\"sampled_{str(0).zfill(6)}.jpg\")).resize((768, 768)))"],"metadata":{"id":"4tPRptklyjxK","executionInfo":{"status":"aborted","timestamp":1691377127537,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from restyle.utils.common import tensor2im\n","from restyle.models.psp import pSp\n","from restyle.models.e4e import e4e\n","\n","downloader.download_file(\"1sw6I2lRIB0MpuJkpc8F5BJiSZrc0hjfE\", os.path.join(pretrained_model_dir, \"restyle_psp_ffhq_encode.pt\"))\n","downloader.download_file(\"1e2oXVeBPXMQoUoC_4TNwAWpOPpSEhE_e\", os.path.join(pretrained_model_dir, \"restyle_e4e_ffhq_encode.pt\"))"],"metadata":{"id":"b-QbLd2Qysyc","executionInfo":{"status":"aborted","timestamp":1691377127538,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_type = 'e4e' #@param['psp', 'e4e']\n","\n","restyle_experiment_args = {\n","    \"model_path\": os.path.join(pretrained_model_dir, f\"restyle_{encoder_type}_ffhq_encode.pt\"),\n","    \"transform\": transforms.Compose([\n","        transforms.Resize((256, 256)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n","}\n","\n","model_path = restyle_experiment_args['model_path']\n","ckpt = torch.load(model_path, map_location='cpu')\n","\n","opts = ckpt['opts']\n","\n","opts['checkpoint_path'] = model_path\n","opts = Namespace(**opts)\n","\n","restyle_net = (pSp if encoder_type == 'psp' else e4e)(opts)\n","\n","restyle_net.eval()\n","restyle_net.cuda()\n","print('Model successfully loaded!')"],"metadata":{"id":"cZYfOJS6yvYa","executionInfo":{"status":"aborted","timestamp":1691377127538,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_alignment(image_path):\n","    import dlib\n","    from scripts.align_faces_parallel import align_face\n","    if not os.path.exists(\"shape_predictor_68_face_landmarks.dat\"):\n","        print('Downloading files for aligning face image...')\n","        os.system('wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2')\n","        os.system('bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2')\n","        print('Done.')\n","    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n","    aligned_image = align_face(filepath=image_path, predictor=predictor)\n","    print(\"Aligned image has shape: {}\".format(aligned_image.size))\n","    return aligned_image\n","\n","def get_avg_image(net):\n","    avg_image = net(net.latent_avg.unsqueeze(0),\n","                    input_code=True,\n","                    randomize_noise=False,\n","                    return_latents=False,\n","                    average_code=True)[0]\n","    avg_image = avg_image.to('cuda').float().detach()\n","    return avg_image\n","\n","opts.n_iters_per_batch = 5\n","opts.resize_outputs = False  # generate outputs at full resolution\n","\n","from restyle.utils.inference_utils import run_on_batch\n"],"metadata":{"id":"iLxavzAgy2zi","executionInfo":{"status":"aborted","timestamp":1691377127538,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_alignment(image_path):\n","    import dlib\n","    from scripts.align_faces_parallel import align_face\n","    if not os.path.exists(\"shape_predictor_68_face_landmarks.dat\"):\n","        print('Downloading files for aligning face image...')\n","        os.system('wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2')\n","        os.system('bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2')\n","        print('Done.')\n","    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n","    aligned_image = align_face(filepath=image_path, predictor=predictor)\n","    print(\"Aligned image has shape: {}\".format(aligned_image.size))\n","    return aligned_image"],"metadata":{"id":"zAbPhNG6y-fK","executionInfo":{"status":"aborted","timestamp":1691377127539,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_avg_image(net):\n","    avg_image = net(net.latent_avg.unsqueeze(0),\n","                    input_code=True,\n","                    randomize_noise=False,\n","                    return_latents=False,\n","                    average_code=True)[0]\n","    avg_image = avg_image.to('cuda').float().detach()\n","    return avg_image\n","\n","opts.n_iters_per_batch = 5\n","opts.resize_outputs = False  # generate outputs at full resolution\n","\n","from restyle.utils.inference_utils import run_on_batch"],"metadata":{"id":"MtvEaZW3zIlB","executionInfo":{"status":"aborted","timestamp":1691377127539,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(image_path):\n","  # image_path = \"/content/drive/MyDrive/drug/ML/content/suzy.png\" #@param {'type': 'string'}\n","  original_image = Image.open(image_path).convert(\"RGB\")\n","\n","  input_image = run_alignment(image_path)\n","\n","  display(input_image)\n","\n","  img_transforms = restyle_experiment_args['transform']\n","  transformed_image = img_transforms(input_image)\n","\n","  with torch.no_grad():\n","    avg_image = get_avg_image(restyle_net)\n","    result_batch, result_latents = run_on_batch(transformed_image.unsqueeze(0).cuda(), restyle_net, opts, avg_image)\n","\n","\n","  #@title Convert inverted image.\n","  inverted_latent = torch.Tensor(result_latents[0][4]).cuda().unsqueeze(0).unsqueeze(1)\n","\n","  with torch.no_grad():\n","      net.eval()\n","\n","      [sampled_src, sampled_dst] = net(inverted_latent, input_is_latent=True)[0]\n","\n","      joined_img = torch.cat([sampled_src, sampled_dst], dim=0)\n","      save_images(joined_img, sample_dir, \"joined\", 2, 0)\n","      display(Image.open(os.path.join(sample_dir, f\"joined_{str(0).zfill(6)}.jpg\")).resize((512, 256)))\n","      return os.path.join(sample_dir, f\"joined_{str(0).zfill(6)}.jpg\");"],"metadata":{"id":"0WK3SLgTzOHV","executionInfo":{"status":"aborted","timestamp":1691377127539,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from flask import Flask, request,jsonify\n","from werkzeug.utils import secure_filename\n","from flask import send_file\n","import os\n","import sys\n","# from models.e4e import predict\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","sys.path.append('/content/drive/MyDrive/drug/ML')\n","\n","!pip install flask-ngrok\n","!pip install pyngrok==4.1.1\n","!ngrok authtoken '294dzGF6SRGFWn5l0brOtz37HvR_2WRzjVis8V5QuYW9A7Gda'\n","!pip install ffmpeg-python\n","from flask_ngrok import run_with_ngrok"],"metadata":{"id":"9zTVos6U7SQ6","executionInfo":{"status":"aborted","timestamp":1691377127539,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# flask\n","def remo_credir():\n","    try:\n","        import shutil\n","        shutil.rmtree('uploaded/image')\n","        print()\n","    except:\n","        pass\n","\n","    try:\n","        os.mkdir('uploaded/image')\n","    except:\n","        pass\n","\n","app = Flask(__name__)\n","run_with_ngrok(app)\n","\n","app.config['JSON_AS_ASCII'] = False # jsonify에서 한글사용\n","app.config['UPLOAD_FOLDER'] = 'content' #경로설정\n","\n","@app.route('/AI', methods=['POST','GET'])\n","def pred():\n","    if request.method == 'POST':\n","        remo_credir()\n","        # 입력받은 사용자 사진 저장\n","        f = request.files['file']\n","        f.save(os.path.join('/content/drive/MyDrive/drug/ML/content/', secure_filename(f.filename)))\n","\n","        # GAN 적용\n","\n","        # 입력받은 사용자 사진 삭제\n","\n","        # 결과 이미지 반환\n","          # image_path = \"/content/drive/MyDrive/drug/ML/content/suzy.png\" #@param {'type': 'string'}\n","        image_path = '/content/drive/MyDrive/drug/ML/content/' + f.filename\n","        result_path=predict(image_path)\n","        return send_file(result_path, mimetype='image/jpeg')\n","    if request.method == 'GET':\n","        return \"get!\"\n","@app.route('/test')\n","def test():\n","  return \"test\"\n","\n","\n","if __name__ == '__main__':\n","    app.run()"],"metadata":{"id":"mljuk6YSyYkm","executionInfo":{"status":"aborted","timestamp":1691377127540,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}}},"execution_count":null,"outputs":[]}]}