{"cells":[{"cell_type":"markdown","metadata":{"id":"gKgdAjRFGWd8"},"source":["# StyleGAN3 Editing\n","\n","- Pixel2Style2Pixel (pSp)\n","- Encoder4Editing (e4e)\n","\n","https://github.com/yuval-alaluf/stylegan3-editing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5FGedphGWd9","executionInfo":{"status":"ok","timestamp":1691116158629,"user_tz":-540,"elapsed":419,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}},"outputId":"75af8e35-0d0c-448c-cb8e-c278263ed7bd","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["content/models/shape_predictor_68_face_landmarks.dat: No such file or directory\n"]}],"source":["!wget -q https://github.com/italojs/facial-landmarks-recognition/raw/master/shape_predictor_68_face_landmarks.dat -O content/models/shape_predictor_68_face_landmarks.dat\n","# https://drive.google.com/file/d/12WZi2a9ORVg-j6d9x4eF-CKpLaURC2W-/view"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jJh1g936GWd-","executionInfo":{"status":"error","timestamp":1691116158921,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hyoin Jeong","userId":"04510042829178422564"}},"outputId":"fe466776-84aa-4f40-a784-e4e945b250d4","colab":{"base_uri":"https://localhost:8080/","height":400}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-9bbe9af5447d>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stylegan3-editing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor2im\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_on_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_average_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malignment_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malign_face\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import sys\n","import pprint\n","import numpy as np\n","from PIL import Image\n","import dataclasses\n","import torch\n","import torchvision.transforms as transforms\n","import dlib\n","\n","sys.path.insert(0, \"stylegan3-editing\")\n","\n","from utils.common import tensor2im\n","from utils.inference_utils import run_on_batch, load_encoder, get_average_image\n","from utils.alignment_utils import align_face"]},{"cell_type":"markdown","metadata":{"id":"Wq5HjBjBGWd-"},"source":["## Load pSp model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2TzP6gwGWd-"},"outputs":[],"source":["encoder, opts = load_encoder(checkpoint_path='content/models/restyle_pSp_ffhq.pt')\n","\n","pprint.pprint(dataclasses.asdict(opts))"]},{"cell_type":"markdown","metadata":{"id":"kyjZlHLTGWd-"},"source":["## Prepare the input image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dehvjhbTGWd_"},"outputs":[],"source":["from PIL import Image\n","\n","img_path = 'content/suzy.jpg'\n","\n","img = Image.open(img_path)\n","\n","img.resize((512, 680))"]},{"cell_type":"markdown","metadata":{"id":"I2cFOmNcGWd_"},"source":["## Align and crop face"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0CpaqlvtGWd_"},"outputs":[],"source":["aligned_img = align_face(\n","    filepath=img_path,\n","    detector=dlib.get_frontal_face_detector(),\n","    predictor=dlib.shape_predictor('content/models/shape_predictor_68_face_landmarks.dat'))\n","\n","aligned_img.resize((512, 512))"]},{"cell_type":"markdown","metadata":{"id":"T8ZvOg8iGWd_"},"source":["## Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HmpMLr8WGWd_"},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n","\n","inputs = transform(aligned_img)\n","inputs = inputs.unsqueeze(0).to('cuda').float()\n","\n","print(inputs.shape)"]},{"cell_type":"markdown","metadata":{"id":"1vPobuPUGWeA"},"source":["## pSp encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSm8rUanGWeA"},"outputs":[],"source":["opts.n_iters_per_batch = 3\n","opts.resize_outputs = False  # generate outputs at full resolution\n","\n","avg_image = get_average_image(encoder)\n","\n","with torch.no_grad():\n","    result_batch, result_latents = run_on_batch(\n","        inputs=inputs,\n","        net=encoder,\n","        opts=opts,\n","        avg_image=avg_image,\n","        landmarks_transform=None)\n","\n","tensor2im(result_batch[0][-1]).resize((512, 512))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mVCd969fGWeA"},"outputs":[],"source":["latent = np.expand_dims(result_latents[0][-1], axis=0)\n","latent = torch.from_numpy(latent).to('cuda').float()\n","\n","print(latent.shape)"]},{"cell_type":"markdown","metadata":{"id":"IuGRoZTMGWeA"},"source":["## Edit the input image using StyleGAN-NADA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E6Wa1TvDGWeA"},"outputs":[],"source":["sys.path.insert(0, 'ZSSGAN')\n","from ZSSGAN.model.ZSSGAN import SG3Generator\n","\n","net = SG3Generator('content/output/Photo_Rotten Zombie/checkpoint/Photo_Rotten Zombie.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YDS1DvvHGWeA"},"outputs":[],"source":["output = net(latent)\n","\n","tensor2im(output[0].squeeze()).resize((512, 512))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-eRmzC9vGWeB"},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"ec526c7dc604f9a80ccfd6581a9c773e8d4624c6a61c30302ea7cf0941fb1ad3"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}